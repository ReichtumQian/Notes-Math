
\section{Solution Structure of Systems of ODEs}

\subsection{Linear Dependence and Wronsky Determinant}

\begin{definition}{Linear Dependence}{}
  Let $\mathbf{x}_1(t),\cdots, \mathbf{x}_k(t)$ be vector functions $\mathbf{x}_i(t): [a,b] \rightarrow \mathbb{R}^n$.
  If there exists $c_1,\cdots,c_k$ that are not all zero such that
  \begin{equation}
    c_1\mathbf{x}_1(t) + \cdots + c_k\mathbf{x}_k(t) = 0, \quad t \in [a, b].
  \end{equation}
  Then $\mathbf{x}_1(t),\cdots,\mathbf{x}_k(t)$ are said to be \emph{linearly dependent}.
  Otherwise, they are said to be \emph{linearly independent}.
\end{definition}

\begin{definition}{Wronsky Determinant}{}
  Let $\mathbf{x}_1(t),\cdots,\mathbf{x}_n(t)$ be $n$ vector functions $\mathbf{x}_i(t): [a,b] \rightarrow \mathbb{R}^n$.
  Then the \emph{Wronsky determinant} is
  \begin{equation}
    W(t) :=
    \begin{vmatrix}
      x_{11}(t) & x_{12}(t) & \cdots & x_{1n}(t)\\
      x_{21}(t) & x_{22}(t) & \cdots & x_{2n}(t)\\
      \vdots & \vdots & & \vdots\\
      x_{n1}(t) & x_{n2}(t) & \cdots & x_{nn}(t)
    \end{vmatrix},
  \end{equation}
  where $x_{ij}$ is the $j$-th component of $\mathbf{x}_i$.
\end{definition}

\subsection{Solution Structure of $\mathbf{x}^{\prime}(t) = A(t) \mathbf{x}(t)$}

\begin{definition}{Fundamental System of Solutions}{}
  Let $\mathbf{x}_1(t),\cdots,\mathbf{x}_n(t)$ be linearly independent vector functions.
  If for any solution $\mathbf{x}(t)$ of $\mathbf{x}^{\prime}(t) = A(t) \mathbf{x}(t)$,
  it can be represented as
  \begin{equation}
    \mathbf{x}(t) = c_1\mathbf{x}_1(t) + \cdots + c_n\mathbf{x}_n(t),
  \end{equation}
  then $\mathbf{x}_1(t),\cdots,\mathbf{x}_n(t)$ are said to be a \emph{fundamental system of solutions}.
\end{definition}

\begin{definition}{Fundamental Solution Matrix}{}
  Let $\mathbf{x}_1(t),\cdots,\mathbf{x}_n(t)$ be the fundamental system of solutions of
  $\mathbf{x}^{\prime}(t) = A(t) \mathbf{x}(t)$,
  then the \emph{fundamental solution matrix} is
  \begin{equation}
    \Phi(t) := 
    \begin{bmatrix}
      x_{11}(t) & x_{12}(t) & \cdots & x_{1n}(t)\\
      x_{21}(t) & x_{22}(t) & \cdots & x_{2n}(t)\\
      \vdots & \vdots & & \vdots\\
      x_{n1}(t) & x_{n2}(t) & \cdots & x_{nn}(t)
    \end{bmatrix},
  \end{equation}
  where $x_{ij}$ is the $j$-th component of $\mathbf{x}_i$.
\end{definition}

\begin{proposition}{Matrix Form of System of ODEs}{}
  Let $\Phi(t)$ be the fundamental solution matrix of $\mathbf{x}^{\prime}(t) = A(t)\mathbf{x}(t)$,
  then
  \begin{equation}
    \Phi^{\prime}(t) = A(t) \Phi(t).
  \end{equation}
\end{proposition}

\begin{proposition}{Solution Structure of $\mathbf{x}^{\prime}(t) = A(t) \mathbf{x}(t)$}{}
  Let $\mathbf{x}_1(t),\cdots,\mathbf{x}_n(t)$ be linearly independent solutions
  of $\mathbf{x}^{\prime}(t) = A(t) \mathbf{x}(t)$.
  Then they are fundamental system of solutions if and only if
  \begin{equation}
    |\Phi(t)| \neq 0, \quad t \in [a,b].
  \end{equation}
  Furthermore, any solution of $\mathbf{x}^{\prime}(t) = A(t)\mathbf{x}(t)$ can be written into matrix forms
  \begin{equation}
    \mathbf{x}(t) = \Phi(t)C, \quad C \in \mathbb{R}^{n \times 1}.
  \end{equation}
\end{proposition}

\begin{example}{}{}
  Define
  \begin{equation}
    \Phi(t) =
      \begin{bmatrix}
        e^t & te^t\\
        0 & e^t
      \end{bmatrix},
      \quad A = 
      \begin{bmatrix}
        1 & 1\\
        0 & 1
      \end{bmatrix}.
  \end{equation}
  Prove that $\Phi(t)$ is a fundamental solution matrix of $\mathbf{x}^{\prime}(t) = A(t)\mathbf{x}(t)$.
\end{example}

\begin{proof}
  Let $\Phi(t) = [\mathbf{x}_1(t), \mathbf{x}_2(t)]$,
  it is not hard to verify that $\mathbf{x}_1(t)$ and $\mathbf{x}_2(t)$ are solutions of
  $\mathbf{x}^{\prime}(t) = A(t) \mathbf{x}(t)$.
  Meanwhile, $|\Phi(t)| \neq 0$, then $\Phi(t)$ is a fundamental solution matrix of $\mathbf{x}^{\prime}(t) = A(t)\mathbf{x}(t)$.
\end{proof}

\subsection{Solution Structure of $\mathbf{x}^{\prime}(t) = A(t) \mathbf{x}(t) + \mathbf{f}(t)$}

\begin{proposition}{Variation of Parameters}{}
  Let $\Phi(t)$ be the fundamental solution matrix of $\mathbf{x}^{\prime}(t) = A(t)\mathbf{x}(t)$,
  then the general solution of $\mathbf{x}^{\prime}(t) = A(t) \mathbf{x}(t) + \mathbf{f}(t)$ is
  \begin{equation}
    \mathbf{x}(t) = \Phi(t)C(t), \quad C(t): [a, b] \rightarrow \mathbb{R}^{n \times 1},
  \end{equation}
  where $C(t)$ follows $C^{\prime}(t) = \Phi^{-1}(t)\mathbf{f}(t)$
  and $C(t_0) = \Phi^{-1}(t_0) \mathbf{x}(t_0)$.
\end{proposition}

\begin{proof}
  Consider $\mathbf{x}(t) = \Phi(t)C(t)$, then
  \begin{equation}
    \mathbf{x}^{\prime}(t) = \Phi^{\prime}(t) C(t) + \Phi(t)C^{\prime}(t), \quad
    A(t)\mathbf{x}(t) + \mathbf{f}(t) = A(t) \Phi(t) C(t) + \mathbf{f}(t).
  \end{equation}
  Since $\Phi^{\prime}(t) = A(t)\Phi(t)$, then
  \begin{equation}
    \mathbf{x}^{\prime}(t) = A(t) \Phi(t)C(t) + \Phi(t)C^{\prime}(t).
  \end{equation}
  Compare the right-hand side and the left-hand side, we get
  \begin{equation}
    \Phi(t)C^{\prime}(t) = \mathbf{f}(t) \Rightarrow C^{\prime}(t) = \Phi^{-1}(t) \mathbf{f}(t).
  \end{equation}
\end{proof}

\begin{example}{}{}
  Find the solutions of
  \begin{equation}
    \mathbf{x}^{\prime} =
    \begin{bmatrix}
      1 & 1\\
      0 & 1
    \end{bmatrix} \mathbf{x} +
    \begin{bmatrix}
      e^{-t}\\
      0
    \end{bmatrix}, \quad
    \mathbf{x}(0) =
    \begin{bmatrix}
      -1 \\
      1
    \end{bmatrix}
  \end{equation}
\end{example}

\begin{solution}
  First, we consider the fundamental solution matrix of $\mathbf{x}^{\prime} = A\mathbf{x}$,
  \begin{equation}
    \Phi(t) =
    \begin{bmatrix}
      e^t & te^t\\
      0 & e^t
    \end{bmatrix} \Rightarrow
    \Phi^{-1}(t) =
    \begin{bmatrix}
      e^{-t} & -te^{-t}\\
      0 & e^{-t}
    \end{bmatrix}
  \end{equation}
  Since $C^{\prime}(t) = \Phi^{-1}(t)\mathbf{f}(t)$ and $C(t_0) = \Phi^{-1}(t_0)\mathbf{x}(t_0)$, i.e.,
  \begin{equation}
    C^{\prime}(t) =
    \begin{bmatrix}
      e^{-2t}\\
      0
    \end{bmatrix}, \quad
    C(0) =
    \begin{bmatrix}
      -1\\
      1
    \end{bmatrix}.
  \end{equation}
  Then $C(t) = \int_{t_0}^t \Phi^{-1}(t)\mathbf{f}(t) \mathrm{d} t + C(t_0)$,
  so $C(t) = (-\frac{1}{2}e^{-2t} - \frac{1}{2}, 1)^T$.
  Then the solution is in the form of
  \begin{equation}
    \mathbf{x}(t) = \Phi(t)C(t) = 
    \begin{bmatrix}
      (t-\frac{1}{2})e^t - \frac{1}{2}e^{-t}\\
      e^t
    \end{bmatrix}.
  \end{equation}
\end{solution}

\section{Solving Constant-Coefficient Systems of ODEs}

\begin{definition}{Matrix Exponential}{}
  Let $A$ be an $n$-order matrix, then its \emph{matrix exponential} is
  \begin{equation}
    e^A := \sum\limits_{n = 0}^{\infty} \frac{A^n}{n!}.
  \end{equation}
\end{definition}

\begin{example}{}{}
  Calculate $e^{A}$, where
  \begin{equation}
    A =
    \begin{bmatrix}
      2 & 1\\
      0 & 2
    \end{bmatrix}
  \end{equation}
\end{example}

\begin{solution}
  Consider $A = B + C$, where
  \begin{equation}
    B =
    \begin{bmatrix}
      2 & 0\\
      0 & 2
    \end{bmatrix}, \quad
    C =
    \begin{bmatrix}
      0 & 1\\
      0 & 0
    \end{bmatrix}.
  \end{equation}
  Then $e^A = e^{B + C} = e^B e^C$, where
  \begin{equation}
    e^B =
    \begin{bmatrix}
      e^2 & 0\\
      0 & e^2
    \end{bmatrix}, \quad
    e^C =
    \begin{bmatrix}
      0 & 1\\
      0 & 0
    \end{bmatrix}
    \Rightarrow
    e^A =
    \begin{bmatrix}
      0 & e^2\\
      0 & 0
    \end{bmatrix}.
  \end{equation}
\end{solution}

\subsection{Solving $\mathbf{x}^{\prime}(t) = A \mathbf{x}(t)$}

\begin{proposition}{Solution Matrix of $\mathbf{x}^{\prime}(t) = A \mathbf{x}(t)$}{}
  The solution matrix of $\mathbf{x}^{\prime}(t) = A \mathbf{x}(t)$ is
  \begin{equation}
    \mathbf{x}(t) = e^{At} c,
  \end{equation}
  where $c \in \mathbb{R}^n$.
\end{proposition}

\begin{example}{}{}
  Find the fundamental solution matrix of
  \begin{equation}
    \mathbf{x}^{\prime} =
    \begin{bmatrix}
      2 & 1\\
      0 & 2
    \end{bmatrix} \mathbf{x}(t).
  \end{equation}
\end{example}

\begin{solution}
  First consider $e^{At}$, let $A = B + C$, then
  \begin{equation}
    e^{At} = e^{Bt}e^{Ct}, \quad
    \text{where} \quad
    B =
    \begin{bmatrix}
      2 & 0\\
      0 & 2
    \end{bmatrix}, C =
    \begin{bmatrix}
      0 & 1\\
      0 & 0
    \end{bmatrix}
    \Rightarrow e^{At} =
    \begin{bmatrix}
      e^{2t} & t\\
      0 & e^{2t}
    \end{bmatrix}.
  \end{equation}
  The fundamental solution matrix $\Phi(t) = e^{At}$.
\end{solution}

\begin{proposition}{Method of Characteristic Equation}{}
  The solution of $\mathbf{x}^{\prime}(t) = A \mathbf{x}(t)$ can be expressed
  by the (generalized) eigenvectors and (generalized) eigenvalues of $A$.
  To be more specific, if $A$ is diagonalizable, then the fundamental solution system is
  \begin{equation}
    e^{\lambda_1 t}\mathbf{v}_1, e^{\lambda_2 t}\mathbf{v}_2 \cdots, e^{\lambda_n t}\mathbf{v}_n,
  \end{equation}
  where $\mathbf{v}_i$ is an eigenvector of $A$ with respect to $\lambda_i$.
  If $A$ is not diagonalizable, then the fundamental solution system is
  \begin{equation}
    e^{\lambda t} \left( \mathbf{v}_0 + t\mathbf{v}_1 + \cdots + \frac{t^k}{k!}\mathbf{v}_k \right),
  \end{equation}
  where $\mathbf{v}_0, \cdots, \mathbf{v}_k$ are generalized eigenvectors corresponding to $\lambda$,
  satisfying $(A - \lambda I)^k \mathbf{v}_k = 0$ and $(A - \lambda I)\mathbf{v}_j = \mathbf{v}_{j-1}$.
\end{proposition}

\begin{proof}
  (1) If $A$ is diagonalizable, then $A$ has $n$ linearly independent eigenvectors
  $\mathbf{v}_1,\cdots,\mathbf{v}_n$. For each $\lambda_i$ and $\mathbf{v}_i$, it is not hard to
  verify that $\mathbf{x}(t) = e^{\lambda_i t}\mathbf{v}_i$ satisfies
  \begin{equation}
    \mathbf{x}^{\prime}(t) = \lambda_i e^{\lambda_i t}\mathbf{v}_i, \quad
    A\mathbf{x}(t) = A (e^{\lambda_i t}\mathbf{v}_i) = e^{\lambda_i t} A\mathbf{v}_i = \lambda_i e^{\lambda_i t}\mathbf{v}_i.
  \end{equation}
  This means $\mathbf{x}(t)$ is a solution of the ODE.
  Furthermore, since $\mathbf{v}_i$ are linearly independent, these solutions form a fundamental solution system.

  (2) Otherwise, there exists an invertible matrix $P$ such that $P^{-1}AP = J$,
  where $J = \operatorname{diag}(J_1,\cdots,J_m)$, where
  \begin{equation}
    J_m =
    \begin{bmatrix}
       \lambda_m & 1 & \cdots & 0 & 0\\
       0 & \lambda_m & \cdots & 0 & 0\\
       \vdots & \vdots & \ddots & \vdots& \vdots\\
       0 &  0& \cdots &\lambda_m & 1\\
       0 &  0& \cdots &0 & \lambda_m
    \end{bmatrix}
    \Rightarrow
    e^{J_m t} = e^{\lambda_m t}
    \begin{bmatrix}
       1 & t & \frac{t^2}{2} & \cdots & \frac{t^{m-1}}{(m-1)!}\\
       0 & 1 & t & \cdots & \frac{t^{m-2}}{(m-2)!}\\
       \vdots & \vdots & \ddots & \ddots & \vdots\\
       0 &  0&  0& 1 & t\\
       0 &  0&  0& 0 & 1
    \end{bmatrix}.
  \end{equation}
  Then $e^{At} = Pe^{J t}P^{-1}$.
\end{proof}

\begin{example}{}{}
  Find the fundamental solution matrix of
  \begin{equation}
    \mathbf{x}^{\prime} =
    \begin{bmatrix}
      -4 & 1 & 0 & 0 & 0\\
      0 & -4 & 1 & 0 & 0\\
      0 & 0 & -4 & 0 & 0\\
      0 & 0 & 0 & -4 & 0\\
      0 & 0 & 0 & 0 & -4\\
    \end{bmatrix} \mathbf{x}.
  \end{equation}
\end{example}

\begin{solution}
  $A$ is already a Jordan matrix composed of three Jordan blocks.
  Consider the first Jordan block, the generalized eigenvectors $\mathbf{v}_1, \mathbf{v}_2, \mathbf{v}_3$ satisfy
  \begin{equation}
    (A + 4I)\mathbf{v}_1 = 0, \quad (A + 4I)\mathbf{v}_2 = \mathbf{v}_1, \quad
    (A + 4I)\mathbf{v}_3 = \mathbf{v}_2.
  \end{equation}
  Solving the above three systems of linear equations, we get
  $\mathbf{v}_1 = \mathbf{e}_1$, $\mathbf{v}_2 = \mathbf{e}_2$ and $\mathbf{v}_3 = \mathbf{e}_3$.
  It is not hard to find the eigenvectors of the second and third Jordan blocks,
  which are $\mathbf{v}_4 = \mathbf{e}_4$ and $\mathbf{v}_5 = \mathbf{e}_5$ respectively.
  Then the fundamental solution system is
  \begin{equation}
    e^{-4t}\mathbf{v}_1,\quad
    e^{-4t}(t\mathbf{v}_1+\mathbf{v}_2),\quad
    e^{-4t}(\frac{t^2}{2}\mathbf{v}_1+t\mathbf{v}_2+\mathbf{v}_3),\quad
    e^{-4t}\mathbf{v}_4,\quad
    e^{-4t}\mathbf{v}_5.
  \end{equation}
  The corresponding fundamental solution matrix is
  \begin{equation}
    \Phi(t) = e^{-4t}
      \begin{bmatrix}
      1 & t & \frac{t^2}{2} & 0 & 0 \\
      0 & 1 & t & 0 & 0 \\
      0 & 0 & 1 & 0 & 0 \\
      0 & 0 & 0 & 1 & 0 \\
      0 & 0 & 0 & 0 & 1
      \end{bmatrix}
  \end{equation}
\end{solution}

\begin{exercise}{}{}
  Find the fundamental solution matrix of
  \begin{equation}
    A = 
    \begin{bmatrix}
    2 & -3 & 3 \\
    4 & -5 & 3 \\
    4 & -4 & 2
    \end{bmatrix}
  \end{equation}
\end{exercise}





