
\section{Concepts and Properties of Sequence Limits}

\subsection{Definition of Sequence Limits}

\begin{definition}{Limits of Sequences}{}
  Consider a sequence of real numbers $a_n$, and a real number $A$.
  We say that the sequence $\{a_n\}$ \emph{converges} to $A$ if
  \begin{equation}
    \forall \epsilon > 0, \exists N \in \mathbb{Z}^+, \forall n > N, |a_n - A| < \epsilon,
  \end{equation}
  denoting as $\lim \limits _{n \rightarrow \infty}a_n = A$.
\end{definition}

\begin{proposition}{Four Arithmetic Operations of Limits}{}
  If the limits $\lim \limits _{n \rightarrow \infty} a_n$ and $\lim \limits _{n \rightarrow \infty} b_n$
  both exist, then
  \begin{equation}
    \lim \limits _{n \rightarrow \infty} (a_n \ast b_n) = \lim \limits _{n \rightarrow \infty} a_n \ast \lim \limits _{n \rightarrow \infty} b_n,
  \end{equation}
  where $\ast$ represents any of four arithmetic operations
  (when it is division, an additional requirement is $\lim \limits _{n
    \rightarrow \infty} b_n \neq 0$).
\end{proposition}

\begin{proof}
  Take the division as an example. Let $\lim \limits _{n \rightarrow \infty} a_n
  = A$ and $\lim \limits _{n \rightarrow \infty} b_n = B \neq 0$, then we
  want to prove that $\frac{a_n}{b_n} \rightarrow \frac{A}{B}$.
  Calculate the difference
  \begin{equation}
    \left|  \frac{a_n}{b_n} - \frac{A}{B}\right| = \frac{|a_nB - Ab_n|}{|b_n B|}.
  \end{equation}
  Since $B \neq 0$, we suppose $|b_n B| > C$,
  then the difference is smaller than $\frac{1}{C} |a_n B - Ab_n|$.
  We add an additional term $AB$
  \begin{equation}
    |a_n B - Ab_n| = |a_n B - AB + AB - Ab_n| \leq |a_n - A|B + A|B - b_n|,
  \end{equation}
  using the definition of sequence limit yields the conclusion.
\end{proof}

\begin{theorem}{Cauchy Criterion for Convergence}{}
  A sequence $\{a_n\}$ converges if and only if
  \begin{equation}
    \forall \epsilon > 0, \exists N \in \mathbb{Z}^+, \forall m,n > N, |a_n - a_m| < \epsilon.
  \end{equation}
\end{theorem}

\begin{corollary}{Contrapositive of Cauchy Criterion for Convergence}{}
  A sequence $\{a_n\}$ does not converge if and only if
  \begin{equation}
    \exists \epsilon > 0, \forall N \in \mathbb{Z}^+, \exists m, n \geq N, |a_n - a_m| \geq \epsilon.
  \end{equation}
\end{corollary}

\begin{example}{Apply the Cauchy Criterion to Prove Divergence}{}
  \begin{enumerate}
  \item Prove that the sequence $\sin n$ diverges.
  \item Prove that the sequence $a_n = 1 + \frac{1}{2} + \cdots + \frac{1}{n}$ diverges.
  \end{enumerate}
\end{example}

\begin{proof}
  (1) Notice that the interval $[2k\pi + \frac{\pi}{4}, 2k\pi + \frac{3\pi}{4}]$
  has a length greater than $1$, so it contains an integer.
  Let $n$ be an integer in this interval
  and $m$ be an integer in $[2k\pi + \pi, 2k\pi + 2\pi]$.
  As $k$ increases, both $n$ and $m$ can go to infinity.
  And we know that $|\sin n - \sin m| \geq \frac{\sqrt{2}}{2}$.
  By the Cauchy convergence criterion, the sequence $\sin n$ diverges.

  (2) For any given $N$, set $n = N$ and $m = 2N$.
  Then $|a_n - a_m| = \sum\limits_{i = N + 1}^{2N} \frac{1}{i} \geq \frac{N}{2N}
  = \frac{1}{2}$.
  Using the contrapositive of the Cauchy criterion criterion,
  we can conclude that the sequence $a_n$ diverges.
\end{proof}

\subsection{Properties of Convergent Sequences}

\begin{proposition}{Properties of Convergent Sequences}{}
  If a sequence $\{a_n\}$ converges to $A$, i.e.,
  $\lim \limits _{n \rightarrow \infty} a_n = A$, then
  \begin{enumerate}
  \item The sequence $a_n$ is bounded;
  \item If $A > a$, then as $n$ approaches infinity, $a_n > a$;
  \item Every sub-sequence of $\{a_n\}$ converges to $A$.
  \end{enumerate}
\end{proposition}

\begin{theorem}{Even and Odd Sub-sequence Convergence}{}
  A sequence $\{a_n\}$ converges to $A$ if and only if both its sub-sequences
  $\{a_{2k}\}$ and $\{a_{2k+1}\}$ converge to $A$.
\end{theorem}

\begin{proof}
  Forward direction is obvious due to the Cauchy criterion for convergence,
  so we only prove the reverse direction.
  Since $\lim \limits _{k \rightarrow \infty} a_{2k} = A$, we have
  \begin{equation}
    \forall \epsilon > 0, \exists K \in \mathbb{Z}^+, \forall k > \frac{K}{2}, |a_{2k} - A| < \epsilon.
  \end{equation}
  For this $\epsilon$, there exists $K^{\prime}$ such that for all $k >
  K^{\prime}$ satisfies $|a_{2k + 1} - A| < \epsilon$.
  Then we choose $N = \max \{K, K^{\prime}\}$, and for all $n > N$ satisfies
  $|a_n - A| < \epsilon$.
\end{proof}

\section{Some Important Sequence Limit Conclusions}

\subsection{Several Basic Limits}

\begin{proposition}{Common Basic Limits}{}
  If $a > 0, b > 1$, the relationships of basic limits are
  $\log n < n^a < b^n < n! < n^n$. Specifically:
  \begin{itemize}
  \item Power-form: $\lim \limits _{n \rightarrow \infty} \sqrt[n]{a} = 1$,
    $\lim \limits _{n \rightarrow \infty} \sqrt[n]{n} = 1$,
    $\lim \limits _{n \rightarrow \infty} \sqrt[n]{n!} = +\infty$.
  \item Ratio-form: $\lim \limits _{n \rightarrow \infty} \frac{a^n}{n!} = 0$,
    $\lim \limits _{n \rightarrow \infty} \frac{n^a}{b^n} = 0 (a > 1)$.
  \item Logarithmic-form: $\lim \limits _{x \rightarrow \infty} \frac{\ln
      x}{x^k} = 0$,
    $\lim \limits _{x \rightarrow 0^+} x^k \ln x = 0$.
  \item Exponential-form: $\lim \limits _{x \rightarrow \infty} \frac{x^k}{e^x}
    = 0$.
  \end{itemize}
\end{proposition}

\begin{proof}
  (1) $\sqrt[n]{n!} \rightarrow +\infty$ due to $n! \sim \left( \frac{n}{e}
  \right)^n$ by Stirling's formula.
\end{proof}

\begin{proposition}{Limits Involving the Number $e$}{}
  $\lim \limits _{n \rightarrow \infty} \left(1 + \frac{1}{n}\right)^n = e$,
  $\lim \limits _{n \rightarrow \infty} (1 + \frac{1}{n})^n = e - \frac{e}{2n} +
  o(\frac{1}{n})$,
  $\lim \limits _{n \rightarrow \infty} \left( 1 - \frac{1}{n} \right)^n = \frac{1}{e}$,
\end{proposition}

\begin{proof}
  (1) Converting the sequence limit to function limit yields
  \begin{equation}
    \lim \limits _{n \rightarrow \infty} \left( 1 + \frac{1}{n} \right)^n
    = \lim \limits _{x \rightarrow 0} (1 + x)^{\frac{1}{x}}
    = \lim \limits _{x \rightarrow 0} e^{\frac{\ln (1 + x)}{x}} = e.
  \end{equation}
\end{proof}

\subsection{Stirling's Formula and Wallis' Formula}

\begin{theorem}{Stirling's Formula}{}
  When the positive integer $n$ approaches infinity,
  the following approximation holds:
  \begin{equation}
    n! \approx \sqrt{2\pi n} \left( \frac{n}{e} \right)^n,
  \end{equation}
  and we can further deduce that $\sqrt[n]{n!} \sim \frac{n}{e}$.
\end{theorem}

\begin{theorem}{Wallis' Formula}{}
  When the positive integer $n$ approaches infinity,
  we have
  \begin{equation}
    \frac{(2n)!!}{(2n - 1)!!} \sim \sqrt{n \pi}.
  \end{equation}
  Moreover, a more precise result is given by
  \begin{equation}
    \lim \limits _{n \rightarrow \infty} \left[
      \frac{(2n)!!}{(2n - 1)!!}
    \right]\frac{1}{2n+1} = \frac{\pi}{2}.
  \end{equation}
\end{theorem}

\subsection{Euler's Constant}

\begin{lemma}{}{}
  The limit
  \begin{equation}
    \lim \limits _{n \rightarrow \infty}
  \left[ (\sum\limits_{k = 1}^n \frac{1}{k}) - \ln n \right]
  \end{equation}
  exists and is finite.
\end{lemma}

\begin{proof}
  Denote $a_n = \sum\limits_{k = 1}^n \frac{1}{k} - \ln n$,
  then we have
  \begin{equation}
    a_n - a_{n-1} = \frac{1}{n} - \ln n + \ln (n-1) = \frac{1}{n} + \ln \frac{n-1}{n} = \frac{1}{n} + \ln (1 - \frac{1}{n}).
  \end{equation}
  By Taylor expansion, we know $\ln (1 - \frac{1}{n}) = - \frac{1}{n} -
  \frac{1}{2n^2} + o(\frac{1}{n^2})$,
  and $a_n - a_{n-1} < 0$ is monotonically decreasing.
  Now we prove that the sequence is bounded:
  \begin{equation}
    \ln n = \ln \frac{n}{n-1} + \ln \frac{n-1}{n-2} + \cdots + \ln \frac{2}{1},
  \end{equation}
  for each $n$, we know that $\ln \frac{n}{n-1} = \ln (1 + \frac{1}{n-1}) <
  \frac{1}{n-1}$,
  thus $a_n > 0$.
  By the monotone convergence theorem, we get the sequence is convergent.
\end{proof}

\begin{definition}{Euler's Constant}{}
  The constant obtained from the above limit is called \emph{Euler's Constant},
  denoted by $\gamma$. Specifically,
  \begin{equation}
    \gamma = \lim \limits _{n \rightarrow \infty} \left[ \sum\limits_{k = 1}^n \frac{1}{k} - \ln n \right].
  \end{equation}
\end{definition}

\begin{corollary}{}{}
  When $n$ approaches infinity, we have
  \begin{equation}
    \sum\limits_{k = 1}^n \frac{1}{k} \approx \ln n + \gamma = \ln n + o(n).
  \end{equation}
\end{corollary}

\section{Criteria for Convergence}

\subsection{Monotone Convergence Theorem}

\begin{theorem}{Monotone Convergence Theorem}{}
  If a sequence $\{a_n\}$ is monotonic and bounded,
  then it must be convergent.
\end{theorem}

\begin{example}{Application of Monotone Convergence Theorem}{}
  Suppose $a_1 = \sqrt{c}, a_{n+1} = \sqrt{a_n + c}$,
  prove that $a_n$ is convergent and
  evaluate $\lim \limits _{n \rightarrow \infty} a_n$.
\end{example}

\begin{solution}
  We prove that $a_n > a_{n-1}$ by induction.
  First $a_2 = \sqrt{c + a_1} = \sqrt{c + \sqrt{c}} > \sqrt{c} = a_1$.
  Assume $a_n > a_{n-1}$, then $a_{n+1} = \sqrt{a_n + c} > \sqrt{a_{n-1} + c} =
  a_n$, we get that $a_n$ is monotonically increasing.
  Suppose the limit of $a_n$ exists and is $A$, then $A$ satisfies $A = \sqrt{A
    + c}$, which means
  \begin{equation}
    A = \frac{1 + \sqrt{1 + 4c}}{2}.
  \end{equation}
  Since $a_n = \sqrt{a_{n-1} + c}$ and $A = \sqrt{A + c}$, if $a_{n-1} < A$,
  then $a_n < A$.
  Thus $a_n$ is bounded and convergent, its limit is $A$.
\end{solution}

\subsection{The Squeeze Theorem}

\begin{theorem}{The Squeeze Theorem}{}
  Let $a_n, b_n, c_n$ be three sequences.
  Suppose there exists an $N \in \mathbb{Z}^+$ such that for all $n \geq N$,
  \begin{equation}
    a_n \leq b_n \leq c_n.
  \end{equation}
  If $\lim \limits _{n \rightarrow \infty} a_n = \lim \limits _{n \rightarrow
    \infty} c_n = A$,
  then 
  \begin{equation}
    \lim \limits _{n \rightarrow \infty} b_n = A.
  \end{equation}
\end{theorem}

\begin{example}{Application of The Squeeze Theorem}{}
  Find $\lim \limits _{n \rightarrow \infty} \frac{1}{2} \cdot
  \frac{3}{4} \cdots \frac{2n-1}{2n}$.
\end{example}

\begin{solution}
  The sequence is monotonically decreasing and positive,
  by monotone convergence theorem we know that the sequence is convergent.
  Now we try to find it limit,
  denote $a_n = \frac{1}{2} \cdot \frac{3}{4} \cdots \frac{2n-1}{2n}$ and $b_n =
  \frac{2}{3} \cdot \frac{4}{5} \cdots \frac{2n}{2n+1}$,
  then $a_n b_n = \frac{1}{2n+1}$ and
  \begin{equation}
    a_n^2 < a_n b_n = \frac{1}{2n+1} \rightarrow 0,
  \end{equation}
  thus $\lim \limits _{n \rightarrow \infty} a_n = 0$.
\end{solution}


\section{Using the Definition of Definite Integral}

\begin{proposition}{}{}
  If $f(x)$ is continuous on $[a,b]$, then
  \begin{equation}
    \lim \limits _{n \rightarrow \infty} \frac{b - a}{n} \left[
      f(a + \frac{b - a}{n}) + f( a + \frac{2(b-a)}{n}) + \cdots + f(a + \frac{n(b-a)}{n})
    \right] = \int_a^b f(x) \mathrm{d} x.
  \end{equation}
\end{proposition}

\begin{example}{Simple Applications}{}
  Find the following limits
  \begin{equation}
    (1) \lim \limits _{n \rightarrow \infty} n \left( \frac{1}{n^2 + 1} + \frac{1}{n^2 + 2} + \cdots + \frac{1}{n^2 + n^2} \right), \quad
    (2) \lim \limits _{n \rightarrow \infty}  \left( \frac{1}{\sqrt{n^2 + 1^2}} + \frac{1}{\sqrt{n^2 + 2^2}} + \cdots + \frac{1}{\sqrt{n^2 + n^2}} \right)
  \end{equation}
\end{example}

\begin{solution}
  (1) We can rewrite the limit into the form of
  \begin{equation}
    \lim \limits _{n \rightarrow \infty} \frac{1}{n^2} \left( \frac{1}{1 + \frac{1}{n^2}} + \frac{1}{1 + \frac{2}{n^2}} \cdots + \frac{1}{1 + 1} \right),
  \end{equation}
  it is equivalent to $\int_0^1 \frac{1}{1 + x^2} \mathrm{d} x = \arctan x
  \big|^1_0 = \frac{\pi}{4}$.

  (2) We can rewrite the limit into the form of
  \begin{equation}
    \lim \limits _{n \rightarrow \infty} \frac{1}{n} \left( \frac{1}{\sqrt{1 + (\frac{1}{n})^2}} + \frac{1}{\sqrt{1 + (\frac{2}{n})^2}} + \cdots + \frac{1}{\sqrt{1 + 1^2}} \right),
  \end{equation}
  it is equivalent to $\int_0^1 \frac{1}{\sqrt{1 + x^2}}\mathrm{d} x = \ln (x +
  \sqrt{x^2 + 1}) \big|^1_0 = \ln (1 + \sqrt{2})$.
\end{solution}

\begin{example}{The Squeeze Theorem + Definition of Definite Integrals}{}
  Find the following limits
  \begin{equation}
    (1) I = \lim \limits _{n \rightarrow \infty} \left( \frac{\sin \frac{\pi}{n}}{n + \frac{1}{n}} + \frac{\sin \frac{2}{n}\pi}{n + \frac{2}{n}} + \cdots + \frac{\sin \pi}{n + 1} \right), \quad
    (2) \lim \limits _{n \rightarrow \infty} \left( \frac{1}{n^2 + n + 1^2} + \frac{2}{n^2 + n + 2^2} + \cdots + \frac{n}{n^2 + n + n^2}\right).
  \end{equation}
\end{example}




