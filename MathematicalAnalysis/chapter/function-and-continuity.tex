
\section{Function Limits}

\subsection{Definition of Function Limits}

\begin{definition}{Function Limit}{}
  Let $x_0 \in \mathbb{R}$, and the function $f$ be defined in the neighborhood
  of $x_0$ (it can be undefined at $x_0$).
  If a real number $A$ satisfies
  \begin{equation}
    \forall \epsilon > 0, \exists \delta > 0, \forall x \in (x_0 - \delta, x_0 + \delta) - \{x_0\},
    |f(x) - A| < \epsilon,
  \end{equation}
  then it is called the \emph{limit} of $f(x)$ at $x = x_0$.
\end{definition}

\begin{example}{Limits of Riemann Function}{}
  Prove that for the Riemann function, for all $x_0 \in [0, 1]$,
  it satisfies $\lim \limits _{x \rightarrow x_0} R(x) = 0$:
  \begin{equation}
    R(x)= \begin{cases}
    \frac{1}{q}, & x = \frac{p}{q} \text{ ($\frac{p}{q}$ is a reduced proper fraction)}; \\
    0, & x \text{ is an irrational number in } (0,1) \text{ or } 0,1 \text{ itself}.
    \end{cases}
  \end{equation}
\end{example}

\begin{proof}
  For all $\epsilon > 0$, there are finite number of $x = \frac{p}{q} \in [0,
  1]$ such that $\frac{1}{q} > \epsilon$,
  denote them as $x_1,\cdots,x_n$.
  Given $x_0 \in [0, 1]$, let $\delta = \min_i |x_0 - x_i|$,
  then
  \begin{equation}
    \forall x \in (x_0 - \delta, x_0 + \delta) - \{x_0\},
    R(x) < \epsilon.
  \end{equation}
  That means $\lim \limits _{x \rightarrow x_0} R(x) = 0$.
\end{proof}

\begin{proposition}{Uniqueness of Function Limits}{}
  If the limit of a function $f(x)$ at $x = x_0$ exists, then it is unique.
\end{proposition}

\begin{proof}
  Suppose there are two limits, and take $\epsilon$ as half of the difference
  between them.
  The proof can be completed according to the definition.
\end{proof}

\subsection{Properties of Function Limits}

\begin{proposition}{Four Arithmetic Operations of Function Limits}{}
  If the limits of $f(x), g(x)$ at $x = x_0$ exists,
  then the limits of $f+g, f-g, f \times g, f/g$
  (limit of the denominator is non-zero for the division operation)
  exist,
  and the limits are the corresponding arithmetic operations of the limits.
\end{proposition}

\begin{proof}
  Omitted since it is similar to that of sequence limit.
\end{proof}

\begin{theorem}{Heine-Cantor Theorem}{}
  The limit of function $f(x)$ at $x = x_0$ is $A$ if and only if
  for any sequence $\{x_n\}$ that converges to $x_0$ satisfying
  \begin{equation}
    \lim \limits _{n \rightarrow \infty} f(x_n) = A.
  \end{equation}
\end{theorem}

\begin{proof}
  Left-to-right is direct, so we only prove the right-to-left direction.
  Assume that $\lim \limits _{x \rightarrow x_0}f(x) \neq A$,
  that is
  \begin{equation}
    \exists \epsilon > 0, \forall \delta \in \mathbb{R}^+,
    \exists x \in (x_0 - \delta, x_0 + \delta) - \{x_0\},
    |f(x) - A| > \epsilon.
  \end{equation}
  Given $\delta_1 \in \mathbb{R}^+$,
  and let $\delta_n = \frac{\delta_{n-1}}{2}$,
  choose $x_n \in (x_0 - \delta_n, x_0 + \delta_n) - \{x_0\}$.
  By the definition of sequence limit, we know that there exists a $\delta > 0$
  such that $|A - f(x_n)| < \epsilon$, which contradicts the assumption.
\end{proof}

\begin{example}{Application of Heine-Cantor Theorem}{}
  Prove that $\lim \limits _{x \rightarrow 0}
  \sin \frac{1}{x}$ does not exist.
\end{example}

\begin{proof}
  Hint: Let $a_n = \frac{1}{2n\pi}$ and $b_n = \frac{1}{2n\pi + \frac{\pi}{2}}$.
\end{proof}

\subsection{Calculation of Function Limits}

\begin{proposition}{Commonly Used Equivalent Infinitesimals}{}
  When $x$ is sufficiently close to $0$, we have
  \begin{equation}
    \begin{array}{lll}
      \sin x \sim x &1 - \cos x \sim \frac{1}{2}x^2 &\tan x \sim x\\
      \arcsin x \sim x & \arctan x \sim x&\\
      \ln(1 + x)\sim x & e^x - 1 \sim x& a^x - 1 \sim x \ln a\\
      (1 + x)^{\alpha} - 1 \sim \alpha x&&
    \end{array}
  \end{equation}
\end{proposition}

\begin{proposition}{Commonly Used Taylor Expansion}{}
  When $x$ is sufficiently close to $0$, we have
  \begin{equation}
    \begin{array}{ll}
    e^x = \sum\limits_{n = 0 }^{\infty}\frac{x^n}{n!}& \ln(1 + x) = \sum\limits_{n = 1}^{\infty}(-1)^{n-1}\frac{x^n}{n} \\
    \sin x = \sum\limits_{n = 0}^{\infty}(-1)^n \frac{x^{2n+1}}{(2n+1)!}& \cos x = \sum\limits_{n = 0}^{\infty}(-1)^n \frac{x^{2n}}{(2n)!} \\
    \arcsin x =\sum\limits_{n = 0}^{\infty}\left( \frac{(2n)!}{2^{2n}(n!)^2} \right)\frac{x^{2n+1}}{2n+1} =  x + \frac{1}{6}x^3 + o(x^3) &\arctan x = \sum\limits_{n = 0}^{\infty} \frac{(-1)^nx^{2n+1}}{2n+1} = x - \frac{1}{3}x^3 + o(x^3) \\
    \frac{1}{1+x} = \sum\limits_{n = 0}^{\infty}(-1)^n x^n&\frac{1}{1 - x} = \sum\limits_{n = 0}^{\infty}x^n \\
    (1+x)^{\alpha} = 1 + \alpha x + \frac{\alpha(\alpha - 1)}{2}x^2 + o(x^2)&(1 + x)^{\alpha} = \sum\limits_{n = 0}^{\infty}{\alpha \choose n} x^n
  \end{array}
  \end{equation}
\end{proposition}


\section{Continuity of Functions}

\subsection{Definition of Function Continuity}

\begin{definition}{Point-Continuity}{}
  Consider a function $f: [a, b] \rightarrow \mathbb{R}$
  and a real number $x_0 \in (a, b)$.
  We say $f(x)$ is \emph{continuous at $x_0$} if
  \begin{equation}
    \lim \limits _{x \rightarrow x_0} f(x) = f(x_0).
  \end{equation}
\end{definition}

\begin{note}
  If a function $f(x)$ is continuous at any point in the interval $(a, b)$,
  then we say it is continuous on $(a, b)$.
\end{note}

\begin{example}{Discontinuity of the Dirichlet Function}{}
  Determine the continuity of the following Dirichlet function:
  \begin{equation}
    D(x) =
    \begin{cases}
      1, & x \text{ is rational}\\
      0, & x \text{ is irrational}.
    \end{cases}
  \end{equation}
\end{example}

\begin{solution}
  Due to the denseness of rational and irrational numbers,
  for any $x \in \mathbb{R}$,
  we can always find two points with a difference of $1$ in any small neighborhood of
  $x$.
  Thus it is discontinuous everywhere.
\end{solution}

\begin{example}{Continuity of the Riemann Function}{}
  Prove that the Riemann function is continuous at irrational points
  and discontinuous at rational points
  \begin{equation}
    R(x) =
    \begin{cases}
      \frac{1}{q}, & x = \frac{p}{q} \text{ is a reduced fraction};\\
      0, & x \text{ is irrational}.
    \end{cases}
  \end{equation}
\end{example}

\begin{proof}
  We have already proven that the limit of the Riemann function is $0$
  at all points in the interval $[0, 1]$,
  thus it is continuous at irrational points and is not continuous at rational points.
\end{proof}

\begin{proposition}{Continuity of Elementary Functions}{}
  Suppose $f, g$ are continuous functions on $[a, b]$,
  then $f^2(x)$, $\sqrt{|f(x)|}$, $|f(x)|$, $\max\{f(x), g(x)\}$, $\min \{f(x), g(x)\}$
  are continuous on $[a, b]$.
\end{proposition}

\begin{proof}
  Hint: $|f(x)| = \sqrt{f^2(x)}$,
  $\max \{f(x), g(x)\} = \frac{1}{2} \left[f(x) + g(x) + |f(x) - g(x)| \right]$.
\end{proof}

\subsection{Intermediate-Value Theorem}

\begin{theorem}{Zero-Point Existence Theorem}{}
  If $f(x)$ is a continuous function on $[a, b]$ and satisfies $f(a)f(b) < 0$,
  then there exists $\xi \in (a, b)$ such that
  \begin{equation}
    f(\xi) = 0.
  \end{equation}
\end{theorem}

\begin{proof}
  We prove it by the Nested Interval Theorem:
  Let $a_1 = a$ and $b_1 = b$, define $c_1 = \frac{a_1 + b_1}{2}$.
  Select $a_2, b_2$ based on the sign of $f(c_1)$,
  and so on.
  Since $\lim \limits _{n \rightarrow \infty} |a_n - b_n| = 0$ and $f(a_n)f(b_n)
  < 0$, by the Nested Interval Theorem,
  when the interval is divided small enough,
  there exists $\xi$ such that $a_n, b_n \rightarrow \xi$, i.e.,
  \begin{equation}
    f^2(\xi) \leq 0,
  \end{equation}
  that means $f(\xi) = 0$.
\end{proof}

\begin{example}{Construct Auxiliary Functions and Apply Zero-Point Existence Theorem}{}
  Prove the following propositions
  \begin{enumerate}
  \item Let $f(x), g(x)$ be continuous functions on $[0, 1]$,
    and have the same maximum value on $[0, 1]$.
    Prove that there exists $\xi \in [0, 1]$ such that $f(\xi) = g(\xi)$.
  \item Let $f(x)$ be a continuous function on $[0, 2a]$,
    and $f(0) = f(2a)$. Prove that there exists $\xi \in [0, a]$ such that
    $f(\xi) = f(\xi + a)$.
  \end{enumerate}
\end{example}

\begin{proof}
  (1) Let $x_1, x_2$ be the points where $f(x)$ and $g(x)$ reach their maximum
  values respectively. If $x_1 = x_2$, then the conclusion is proved.
  If $x_1 \neq x_2$, then take $F(x) = f(x) - g(x)$. We know $F(x_1) \geq 0,
  F(x_2) \leq 0$. The conclusion follows from the zero-point existence theorem.

  (2) Take $F(x) = f(x) - f(x+a)$, then we have $F(0) = f(0) - f(a)$ and $F(a) =
  f(a) - f(2a) = f(a) - f(0)$.
  This indicates that $F(0) = -F(a)$, and the conclusion follows from the
  zero-point existence theorem.
\end{proof}

\begin{theorem}{Intermediate-Value Theorem}{}
  If $f(x)$ is a continuous function on $[a, b]$,
  then for two points $x_1, x_2$ satisfying $a \leq x_1 < x_2 \leq b$ and
  $f(x_1) \neq f(x_2)$,
  $f(x)$ can take any value between $f(x_1)$ and $f(x_2)$ on $[a, b]$.
\end{theorem}


\section{Uniform Continuity of Functions}

\subsection{Definition of Uniform Continuity}

\begin{definition}{Uniform Continuity}{}
  Let $I$ be an arbitrary interval,
  and let $f$ be a function $f: I \rightarrow \mathbb{R}$.
  If for any $\epsilon > 0$, there exists $\delta > 0$ such that for all $x_1,
  x_2 \in I$, when $|x_1 - x_2| < \delta$, we have
  \begin{equation}
    |f(x_1) - f(x_2)| < \epsilon,
  \end{equation}
  then $f$ is said to be \emph{uniformly continuous} on $I$.
\end{definition}

\begin{proposition}{Sequence Perspective}{}
  Let $f(x)$ be a function defined on $I$,
  then $f(x)$ is uniformly continuous on $I$ if and only if
  for any sequences $x_n, y_n$ in $I$,
  if $\lim \limits _{n \rightarrow \infty} (x_n - y_n) = 0$,
  then
  \begin{equation}
    \lim \limits _{n \rightarrow \infty} \left[ f(x_n) - f(y_n) \right] = 0.
  \end{equation}
\end{proposition}

\begin{proof}
  From left to right is obvious, so we only prove the reverse direction.
  Assume $f$ is not uniformly continuous,
  then there exists $\epsilon_0 > 0$, for any $\delta > 0$,
  there exist $x, y$ such that $|x - y| < \delta$, but
  \begin{equation}
    |f(x) - f(y)| \geq \epsilon_0.
  \end{equation}
  Take $\delta = 1, \frac{1}{2}, \cdots, \frac{1}{n}$, there exist $x_n, y_n$
  such that $|x_n - y_n| < \frac{1}{n}$ and $|f(x_n) - f(y_n)| \geq \epsilon_0$,
  which contradicts the given condition.
\end{proof}

\begin{note}
  In most cases, the above theorem is used to prove that
  a function is not uniformly continuous.
\end{note}

\begin{example}{Examples of Continuous but Not Uniformly Continuous Functions}{}
  Prove the following functions are not uniformly continuous:
  (1) $x^2$ on $(0, +\infty)$,
  (2) $\sin x^2$ on $[0, + \infty)$,
  (3) $\frac{1}{x}$ on $(0, 1)$.
\end{example}

\begin{proof}
  (1) Take $x_n = \sqrt{n}, y_n = \sqrt{n + 1}$;
  (2) Take $x_n = \sqrt{2n \pi}, y_n = \sqrt{2n \pi + \frac{\pi}{2}}$;
  (3) Take $x_n = \frac{1}{n}, y_n = \frac{1}{n+1}$.
\end{proof}

\begin{example}{Prove Uniform Continuity}{}
  Prove that the following functions are uniformly continuous:
  (1) $\cos \sqrt{x}$ on $[0, +\infty)$
  (2) $\sqrt{x}$ on $[0, +\infty)$
  (3) $\sin x$ on $[0, +\infty)$.
\end{example}

\begin{proof}
  Hint: Use the definition of uniform continuity.
\end{proof}

\subsection{Cantor Theorem and Its Generalization}

\begin{theorem}{Cantor Theorem}{}
  If $f(x)$ is continuous on the closed interval $[a, b]$,
  then it is uniformly continuous on $[a, b]$.
\end{theorem}

\begin{theorem}{Cantor Theorem on an Infinite Interval}{}
  If $f(x)$ is continuous on $[a, +\infty)$,
  and $\lim \limits _{x \rightarrow +\infty} f(x) = A$,
  then $f(x)$ is uniformly continuous on $[a, +\infty)$.
\end{theorem}

\subsection{Lipschitz Continuity}

\begin{definition}{Lipschitz Continuity}{}
  If a function $f(x): I \rightarrow \mathbb{R}$
  satisfies the Lipschitz condition, i.e.,
  there exists a positive real number $L$ such that
  for any $x_1, x_2 \in I$,
  \begin{equation}
    |f(x_1) - f(x_2)| \leq L |x_1 - x_2|.
  \end{equation}
  Then it is \emph{Lipschitz continuous} on $I$.
\end{definition}

\begin{proposition}{Lipschitz Continuity and Uniform Continuity}{}
  If $f(x)$ is Lipschitz continuous on the interval $I$,
  then it is uniformly continuous on $I$.
\end{proposition}

\begin{proof}
  Based on the Lipschitz continuity, for all $\epsilon > 0$,
  take $\delta = \frac{\epsilon}{L}$, then we have
  \begin{equation}
    |f(x) - f(y)| \leq L \cdot \frac{\epsilon}{L} = \epsilon.
  \end{equation}
  Thus $f(x)$ is uniformly continuous.
\end{proof}

\begin{corollary}{Bounded Derivative Implies Uniform Continuity}{}
  If $f^{\prime}(x)$ is bounded on $I$, then $f(x)$ is Lipschitz continuous and
  uniformly continuous.
\end{corollary}

\begin{example}{Use Lipschitz Continuity to Prove Uniform Continuity}{}
  Determine the uniform continuity of
  (1) $\sin x$ on $\mathbb{R}$;
  (2) $x^k$ on $(1, +\infty)$;
  (3) $\cos \sqrt{x}$ on $(1, +\infty)$;
  (4) $x \ln x$ on $(0, +\infty)$.
\end{example}

\begin{solution}
  (1) $\sin x$ is uniformly continuous since its derivative is bounded.
\end{solution}

